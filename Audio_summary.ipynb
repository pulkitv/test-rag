{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP7l29j8wYNgQzRTW1/a+zf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pulkitv/test-rag/blob/main/Audio_summary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28\n",
        "!pip install pyannote.audio\n",
        "!pip install openai-whisper\n",
        "\n",
        "!pip install torch==1.10.0+cu102\n",
        "!pip install pyannote.audio==0.0.1\n",
        "\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install gtts\n",
        "!pip install pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "id": "kEdn-unu7SWG",
        "outputId": "1f1e271a-66d4-4ec9-89db-0e7e86a21a52"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.11/dist-packages (2.38.0)\n",
            "Collecting google-auth\n",
            "  Downloading google_auth-2.39.0-py2.py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.11/dist-packages (1.2.1)\n",
            "Requirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (2.164.0)\n",
            "Collecting google-api-python-client\n",
            "  Downloading google_api_python_client-2.167.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib) (2.0.0)\n",
            "Requirement already satisfied: httplib2>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-httplib2) (0.22.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (2.24.2)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (4.1.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (5.29.4)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.26.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.32.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2>=0.19.0->google-auth-httplib2) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2025.1.31)\n",
            "Downloading google_auth-2.39.0-py2.py3-none-any.whl (212 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.3/212.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_api_python_client-2.167.0-py2.py3-none-any.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m115.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: google-auth, google-api-python-client\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 2.38.0\n",
            "    Uninstalling google-auth-2.38.0:\n",
            "      Successfully uninstalled google-auth-2.38.0\n",
            "  Attempting uninstall: google-api-python-client\n",
            "    Found existing installation: google-api-python-client 2.164.0\n",
            "    Uninstalling google-api-python-client-2.164.0:\n",
            "      Successfully uninstalled google-api-python-client-2.164.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.39.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-api-python-client-2.167.0 google-auth-2.39.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "fa0bb6309081454abb1537db0769cece"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "# GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "# GOOGLE_CSE_ID = userdata.get('GOOGLE_CSE_ID')\n",
        "# ACTIVELOOP_TOKEN = userdata.get('ACTIVELOOP_TOKEN')\n",
        "# LANGCHAIN_API_KEY = userdata.get('LANGCHAIN_API_KEY')\n",
        "HUGGINGFACE_API_KEY = userdata.get('HUGGINGFACE_API_KEY')\n",
        "GMAIL_PASSWORD = userdata.get('GMAIL_PASSWORD')\n",
        "\n",
        "\n",
        "# os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "# os.environ[\"GOOGLE_CSE_ID\"] = GOOGLE_CSE_ID\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "# os.environ[\"ACTIVELOOP_TOKEN\"] = ACTIVELOOP_TOKEN\n",
        "# os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
        "os.environ[\"HUGGINGFACE_API_KEY\"] = HUGGINGFACE_API_KEY\n",
        "os.environ[\"GMAIL_PASSWORD\"] = GMAIL_PASSWORD\n",
        "\n",
        "print(\"Done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvajPgUj3fVl",
        "outputId": "5c55bfa6-8ef8-4702-d9c0-f7ab97161031"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "# Upload audio file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Move the uploaded file to the working directory\n",
        "audio_file_path = list(uploaded.keys())[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "gr6k0iDd2zII",
        "outputId": "1b792968-3d38-4bcb-d645-d0ead1f1c9f3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ee196dc0-081b-470a-8061-555560d3c774\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ee196dc0-081b-470a-8061-555560d3c774\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Fluent English conversation with buddy2.mp3 to Fluent English conversation with buddy2 (3).mp3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "from pyannote.audio.pipelines import SpeakerDiarization\n",
        "from pyannote.core import Segment\n",
        "import torch\n",
        "import warnings\n",
        "import logging\n",
        "\n",
        "# Suppress FP16 warning on CPU\n",
        "warnings.filterwarnings(\"ignore\", message=\"FP16 is not supported on CPU\")\n",
        "\n",
        "# Suppress PyTorch warnings and logs\n",
        "logging.getLogger(\"torch\").setLevel(logging.ERROR)\n",
        "\n",
        "# Suppress SpeechBrain and pyannote logging\n",
        "logging.getLogger(\"speechbrain\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"pyannote\").setLevel(logging.ERROR)\n",
        "\n",
        "# Load Whisper model for transcription\n",
        "model = whisper.load_model(\"base\")\n",
        "\n",
        "# Perform transcription with Whisper and get word-level timestamps\n",
        "result = model.transcribe(audio_file_path, word_timestamps=True)\n",
        "\n",
        "# Get Whisper's word-level segments (start, end, and text)\n",
        "segments = result['segments']  # This contains the start, end, and text of each segment\n",
        "\n",
        "# Load pyannote's pre-trained speaker diarization model\n",
        "pipeline = SpeakerDiarization.from_pretrained(\"pyannote/speaker-diarization@2.1\", use_auth_token=HUGGINGFACE_API_KEY)\n",
        "\n",
        "# Move pipeline to GPU if available\n",
        "if torch.cuda.is_available():\n",
        "    pipeline.to(torch.device(\"cuda\"))\n",
        "    print(\"Pipeline is moved to GPU.\")\n",
        "else:\n",
        "    print(\"GPU not available. Using CPU.\")\n",
        "\n",
        "# Perform speaker diarization on the audio\n",
        "diarization = pipeline(audio_file_path)\n",
        "\n",
        "# Create a list to store the formatted conversation\n",
        "conversation = []\n",
        "\n",
        "# Iterate through diarization and match with transcription segments\n",
        "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
        "    # Convert the start and end times to integer indices\n",
        "    start_time = int(turn.start)\n",
        "    end_time = int(turn.end)\n",
        "\n",
        "    # Match the transcription segments by checking if the timestamps overlap with diarization times\n",
        "    segment_text = \"\"\n",
        "    for segment in segments:\n",
        "        if segment['start'] >= start_time and segment['end'] <= end_time:\n",
        "            segment_text += segment['text'] + \" \"\n",
        "\n",
        "    # Append the formatted conversation\n",
        "    conversation.append(f\"Speaker {speaker}: {segment_text.strip()}\")\n",
        "\n",
        "# Print the formatted conversation\n",
        "for entry in conversation:\n",
        "    print(entry)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuEbMpJINLrB",
        "outputId": "ebc77263-7960-493e-e5c8-19157f92d20f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.5.1. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../root/.cache/torch/pyannote/models--pyannote--segmentation/snapshots/c4c8ceafcbb3a7a280c2d357aee9fbc9b0be7f9b/pytorch_model.bin`\n",
            "INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/hyperparams.yaml'\n",
            "INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model was trained with pyannote.audio 0.0.1, yours is 3.3.2. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.6.0+cu124. Bad things might happen unless you revert torch to 1.x.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:speechbrain.utils.parameter_transfer:Collecting files (or symlinks) for pretraining in /root/.cache/torch/pyannote/speechbrain.\n",
            "INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt'\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"embedding_model\"] = /root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt\n",
            "INFO:speechbrain.utils.fetching:Fetch mean_var_norm_emb.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt'\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"mean_var_norm_emb\"] = /root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt\n",
            "INFO:speechbrain.utils.fetching:Fetch classifier.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/classifier.ckpt'\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"classifier\"] = /root/.cache/torch/pyannote/speechbrain/classifier.ckpt\n",
            "INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt'\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"label_encoder\"] = /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n",
            "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): embedding_model -> /root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): mean_var_norm_emb -> /root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): classifier -> /root/.cache/torch/pyannote/speechbrain/classifier.ckpt\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): label_encoder -> /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n",
            "DEBUG:speechbrain.dataio.encoder:Loaded categorical encoding from /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n",
            "INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/hyperparams.yaml'\n",
            "INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Collecting files (or symlinks) for pretraining in /root/.cache/torch/pyannote/speechbrain.\n",
            "INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt'\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"embedding_model\"] = /root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt\n",
            "INFO:speechbrain.utils.fetching:Fetch mean_var_norm_emb.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt'\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"mean_var_norm_emb\"] = /root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt\n",
            "INFO:speechbrain.utils.fetching:Fetch classifier.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/classifier.ckpt'\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"classifier\"] = /root/.cache/torch/pyannote/speechbrain/classifier.ckpt\n",
            "INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt'\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"label_encoder\"] = /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n",
            "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): embedding_model -> /root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): mean_var_norm_emb -> /root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): classifier -> /root/.cache/torch/pyannote/speechbrain/classifier.ckpt\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): label_encoder -> /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n",
            "DEBUG:speechbrain.dataio.encoder:Loaded categorical encoding from /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline is moved to GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchaudio/_backend/soundfile_backend.py:71: UserWarning: The MPEG_LAYER_III subtype is unknown to TorchAudio. As a result, the bits_per_sample attribute will be set to 0. If you are seeing this warning, please report by opening an issue on github (after checking for existing/closed ones). You may otherwise ignore this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speaker SPEAKER_00: So this story I still remember of you that you said in your village initially people were not  treating you well like not giving you respect but after they came to know that you speak very good English  Everything has changed. They started giving you a huge respect and everything. I still remember that story actually  So actually I wanted no more on that like did you face only that issue or\n",
            "Speaker SPEAKER_01: \n",
            "Speaker SPEAKER_01: First of all, I never wish start any conversation. I never ever demonstrate that oh, I can speak English  I always look for opportunities. You don't show off. Okay. What is the need?\n",
            "Speaker SPEAKER_00: \n",
            "Speaker SPEAKER_00: \n",
            "Speaker SPEAKER_00: And but I am the opposite I show off all the time  Okay, look at my English\n",
            "Speaker SPEAKER_01: \n",
            "Speaker SPEAKER_01: I never ever do that  I\n",
            "Speaker SPEAKER_01: \n",
            "Speaker SPEAKER_01: If I feel yes, I need to take the call. I need to start the conversation. I certainly do that\n",
            "Speaker SPEAKER_01: Okay, I would never ever do that if anyone says anything in English. I make sure  I then I show that what I know  Then I start that conversation and I think that this is what I really enjoy  I never ever start that conversation when I go to hospitals  And sometimes I know that these people are highly educated. These people must be proficient in English  Then I don't miss the boat. I\n",
            "Speaker SPEAKER_00: \n",
            "Speaker SPEAKER_00: So I went to this restaurant in Bangalore and I was like oh my god  I'm that's my nature  I always try to show off a little bit not very much  So I went to the restaurant. I called the waiter  Hello, sir. Can you come here? Something like that. I was speaking in English and everybody was looking at me  Oh, this guy speaks  Must be a very high class guy or something  And then I came to know the waiter doesn't understand English  Yes, so I was like it was like a bummer for me. I was like\n",
            "Speaker SPEAKER_00: Let's say like a wonderful experience. It's not it's not about whether you speak English or not  The other person should also understand English a little bit\n",
            "Speaker SPEAKER_01: Yes, this is the thing and I would also like to add one thing  With your leave\n",
            "Speaker SPEAKER_00: \n",
            "Speaker SPEAKER_01: I  Let people take me for granted  Because I usually represent myself that the person might not be aware of this language that person might not speak\n",
            "Speaker SPEAKER_01: Then I usually prove these people wrong  Sometimes you must have experienced people those who are good at English\n",
            "Speaker SPEAKER_00: Yeah, that I know yes, I've experienced that I mean  Some people they what they do is they actively oppress them some people they unconsciously do it  They just simply make a joke on it. Oh, your English is not good. Oh, you should have used this sentence  They try to correct you whenever you speak in English, but they are also in your same level\n",
            "Speaker SPEAKER_00: \n",
            "Speaker SPEAKER_01: \n",
            "Speaker SPEAKER_01: No offense, but girls often do it  Okay  Okay  Yes, they usually pretend they are superior to everyone  They pronounce words or they usually start the conversation in English where it is not required\n",
            "Speaker SPEAKER_00: \n",
            "Speaker SPEAKER_00: \n",
            "Speaker SPEAKER_00: \n",
            "Speaker SPEAKER_00: \n",
            "Speaker SPEAKER_00: I've experienced this actual thing I've experienced in my school when I was studying six standard  6th or 7th standard where I have this huge crush on this girl  She always speaks English. Yeah, she speaks broken English, but she speaks only English  And one of our English teachers, you know, I'm her favorite student  She always wants me to learn English, but I never learned English that time  She came to know that she speaks only English and  She says you know they see you're speaking broken English, but that is good look at these boys. They don't even speak English  At least you're trying this much that is really good. You keep continuing that later after sometime\n",
            "Speaker SPEAKER_00: You know, I had a chance to meet them. She's married and she settles somewhere  I had a chance to meet them then I told them about my English YouTube channel  You're not even able to speak English during schools now you're having YouTube channel. Wow, that's great\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"] # Replace 'your-openai-api-key' with your actual API key or better yet, store it as env variable\n",
        "\n",
        "# Function to generate the summary using GPT-3.5 or GPT-4\n",
        "def summarize_text(text):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",  # Use gpt-3.5-turbo instead of the deprecated text-davinci-003\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a personal AI assistant who is hired to take notes and summarize meetings for future reference. Assume that the transcription provided is of a business meeting.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Summarize the following conversation (from an audio recording) without missing any important details. Segregate if there are multiple topics discussed. Each topic with their heading. List out any action items at the end separately for each speaker. Do not ask any follow up questions: {text}\"}\n",
        "        ],\n",
        "        max_tokens=300\n",
        "    )\n",
        "    return response.choices[0].message['content'].strip()\n",
        "\n",
        "# Assuming transcribed_text is the result from your transcription model (e.g., Whisper)\n",
        "# transcribed_text = \"Your transcribed text goes here\" #Use the output from Whisper instead of this hardcoded value\n",
        "# Assuming transcribed_text is already defined from your previous Whisper transcription step\n",
        "# transcribed_text = result['text']\n",
        "\n",
        "# Get the summary\n",
        "summary = summarize_text(conversation)\n",
        "print(\"Summary: \", summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7lJaasg3KZO",
        "outputId": "17caa139-79be-4145-ce50-99825dae8957"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:  ### English Proficiency and Perception\n",
            "- **Speaker SPEAKER_00** recalls a story where initially in their village, they were not treated well until it was discovered they spoke English well. This changed how they were perceived, gaining them respect.\n",
            "- **Speaker SPEAKER_01** mentions they never show off their English skills, only using them when necessary. They dislike pretentious displays of fluency.\n",
            "\n",
            "### Social Perceptions and Behavior\n",
            "- **Speaker SPEAKER_00** shares an experience in a restaurant where speaking English led to assumptions about their status until they realized the waiter didn't understand English.\n",
            "- **Speaker SPEAKER_01** emphasizes the importance of mutual understanding in communication, irrespective of language proficiency.\n",
            "\n",
            "### Gender and Language Dynamics\n",
            "- **Speaker SPEAKER_01** notes that some women may behave superior in language interactions when it's not necessary, potentially making others feel inadequate.\n",
            "- **Speaker SPEAKER_00** recounts experiences from their school days, where a girl's English proficiency influenced perceptions, with the English teacher encouraging the effort to speak the language.\n",
            "\n",
            "### Action Items:\n",
            "- **Speaker SPEAKER_00:** Reflects on experiences where English proficiency influenced social dynamics. No specific action items mentioned.\n",
            "- **Speaker SPEAKER_01:** Shares insights on language interactions. No specific action items mentioned.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import smtplib\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.text import MIMEText\n",
        "import os\n",
        "\n",
        "# Function to send email\n",
        "def send_email(conversation, summary):\n",
        "    # Set up the server\n",
        "    smtp_server = \"smtp.gmail.com\"  # Using Gmail's SMTP server\n",
        "    smtp_port = 587  # Standard SMTP port for TLS\n",
        "    sender_email = \"vashishta.pulkit@gmail.com\"  # Your Gmail email address\n",
        "    receiver_email = \"vashishta.pulkit@gmail.com\"  # Receiver's email address\n",
        "    email_password = GMAIL_PASSWORD  # Your Gmail App Password (generated from Google account)\n",
        "\n",
        "    # Create the email content\n",
        "    subject = \"Meeting Summary and Conversation\"\n",
        "    body = f\"\"\"\n",
        "    <h2>Conversation:</h2>\n",
        "    <pre>{conversation}</pre>\n",
        "\n",
        "    <h2>Summary:</h2>\n",
        "    <pre>{summary}</pre>\n",
        "    \"\"\"\n",
        "\n",
        "    # Create MIME message\n",
        "    msg = MIMEMultipart()\n",
        "    msg['From'] = sender_email\n",
        "    msg['To'] = receiver_email\n",
        "    msg['Subject'] = subject\n",
        "\n",
        "    # Attach the body to the email\n",
        "    msg.attach(MIMEText(body, \"html\"))\n",
        "\n",
        "    # Connect to the server and send the email\n",
        "    try:\n",
        "        with smtplib.SMTP(smtp_server, smtp_port) as server:\n",
        "            server.starttls()  # Secure the connection\n",
        "            server.login(sender_email, email_password)  # Log in to your email account\n",
        "            server.sendmail(sender_email, receiver_email, msg.as_string())  # Send the email\n",
        "            print(\"Email sent successfully!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "# Send the email\n",
        "send_email(conversation, summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbILMa_a5bmX",
        "outputId": "5333cedf-8355-4d99-83e3-e32aa596384b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Email sent successfully!\n"
          ]
        }
      ]
    }
  ]
}